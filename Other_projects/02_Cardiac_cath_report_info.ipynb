{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Selecting MGH Cath reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##septal\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 120)\n",
    "pd.set_option('display.max_columns', 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML         #allows printing of notes with line breaks (*not helpful for cath reports?)\n",
    "\n",
    "def pretty_print(df):\n",
    "    return display(HTML( df.to_html().replace(\"\\\\n\",\"<br>\") ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=('/mnt/obi0/phi/ehr/pre-sysmex_Hx_labeling/data/jgt-make_CADHx_labelling_questionnaire_20191217_JJ_out__jj.csv')  \n",
    "df = pd.read_csv(file)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0  score_CAD                                            methods\n",
      "0  Z11211310          1  Found a pre-Sysmex note that specified that pa...\n",
      "1  Z11014558          1  Note immediately before Sysmex specifies that ...\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_notes = \"/mnt/obi0/phi/ehr/note_pull/parquet\"      #finds all files in folder\n",
    "\n",
    "files = []\n",
    "for r, d, f in os.walk(path_notes):\n",
    "    for file in f:\n",
    "        files.append(os.path.join(file))\n",
    "\n",
    "#for f in files:\n",
    "#    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.sort()                         #appends files starting with MGH_cath to cathfiles\n",
    "\n",
    "cathfiles = []\n",
    "\n",
    "for f in files:\n",
    "    if f.startswith('MGH_cath'):\n",
    "        cathfiles.append(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df = pd.DataFrame()                  #adds cath reports from each parquet file to cathnotes_df\n",
    "\n",
    "for cathfile in cathfiles:\n",
    "    file= \"/mnt/obi0/phi/ehr/note_pull/parquet/\" + cathfile\n",
    "    dfnotes = pd.read_parquet(file)\n",
    "    dfnotes[\"Stenosis\"] = 0\n",
    "    dfnotes=dfnotes.sort_values(by=['PatientID'], ascending=True)\n",
    "    cathnotes_df = cathnotes_df.append(dfnotes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df.shape                           #596,900 notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df = cathnotes_df[cathnotes_df['NoteTXT'].str.contains('CARDIAC CATHETERIZATION LABORATORY FINAL REPORT', case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df.shape                           #19968 labeled \"Cardiac cath lab final report\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_nosummary = cathnotes_df[~cathnotes_df['NoteTXT'].str.contains('CORONARY ANATOMY FINDINGS', case=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_nosummary.shape                    #8141 without 'coronary anatomy findings' section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_nosummary2 = cathnotes_nosummary[~cathnotes_nosummary['NoteTXT'].str.contains('Right heart catheterization | RHC | RHC, | peripheral | biopsy | pericardial | pericardiocentesis | aborted | thrombolysis | pulmonary embolism | valve | MV | occluder | device | PFO | pacemaker | IABP | transseptal', case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_nosummary2.shape                    #120, of which approx 1/3 do have a diagnostic cath summary, but not in typical template format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df = cathnotes_df[cathnotes_df['NoteTXT'].str.contains('CORONARY ANATOMY FINDINGS', case=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df.shape                           #11,827 with \"coronary anatomy findings\" section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_incomplete = cathnotes_df[~cathnotes_df['NoteTXT'].str.contains('(?= .*Left Main:)(?= .*LAD:)(?= .*Left Circumflex:)(?= .*RCA:)', case=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_incomplete.shape                   #598 without all 4 vessel sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df = cathnotes_df[cathnotes_df['NoteTXT'].str.contains('Left Main:', case=True)]\n",
    "cathnotes_df = cathnotes_df[cathnotes_df['NoteTXT'].str.contains('LAD:', case=True)]\n",
    "cathnotes_df = cathnotes_df[cathnotes_df['NoteTXT'].str.contains('Left Circumflex:', case=True)]\n",
    "cathnotes_df = cathnotes_df[cathnotes_df['NoteTXT'].str.contains('RCA:', case=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df.shape                          #11,575 with all 4 vessel sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df = cathnotes_df[~cathnotes_df['NoteTXT'].str.contains('transplant', case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df.shape                          #10,581 after excluding transplant cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df = cathnotes_df[~cathnotes_df['NoteTXT'].str.contains('SVG|LIMA', case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df.shape                          #8879 after excluding CABG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df = cathnotes_df[~cathnotes_df['NoteTXT'].str.contains('Coronary Anomaly:', case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df.shape                          #8724 after excluding anomalous coronary cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df[\"Stenosis\"] = cathnotes_df['NoteTXT'].str.contains('stenosis|stenoses', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdatefiles = []                            #concatenates date files\n",
    "\n",
    "for datefile in Path('/mnt/obi0/phi/ehr/cath_reports/').glob('MGH_cath_stenosis_*'):\n",
    "    with open(datefile) as infile:\n",
    "        dfdatefiles.append(pd.read_csv(infile, sep='\\t', header=None))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdates = pd.concat(dfdatefiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdates.columns = ['PatientID', 'MRN', 'date', 'NoteID']\n",
    "dfdates.iloc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cathnotes_df['NoteID'] = pd.to_numeric(cathnotes_df['NoteID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(cathnotes_df, dfdates, on='NoteID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('PatientID_y', axis=1, inplace=True)  #also maybe drop 'PatientEncounterID', 'InpatientNoteTypeDSC', 'LastFiledDTS', 'CurrentAuthorID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cathresults(cathnote):\n",
    "    text = cathnote.NoteTXT\n",
    "    notestart = text.find('CORONARY ANATOMY FINDINGS')\n",
    "    domstart = text.find('Dominance:', notestart)\n",
    "    leftmainstart = text.find('Left Main:', notestart)\n",
    "    ladstart = text.find('LAD:', notestart)\n",
    "    circumflexstart = text.find('Left Circumflex:', notestart)\n",
    "    rcastart = text.find('RCA:', notestart)\n",
    "    \n",
    "    endcaps = re.compile(r'[A-Z][A-Z][A-Z][A-Z]')\n",
    "    endcapsmatch = endcaps.finditer(text)\n",
    "    endindices = []\n",
    "    position = []\n",
    "    for capsmatch in endcapsmatch:\n",
    "        endindices.append(capsmatch.start())\n",
    "        #print(capsmatch.start())\n",
    "    for endindex in endindices:\n",
    "        if endindex > rcastart:\n",
    "            position = endindex\n",
    "            break\n",
    "    \n",
    "    \n",
    "    dominance = text[domstart+11 : leftmainstart]\n",
    "    if domstart== -1: \n",
    "        dominance = ''\n",
    "    leftmain = text[leftmainstart+11 : ladstart]\n",
    "    lad = text[ladstart+5 : circumflexstart-5]\n",
    "    circumflex = text[circumflexstart + 17 : rcastart]\n",
    "    rca = text[rcastart + 5 : position]\n",
    "    \n",
    "    dominance = dominance.strip()\n",
    "    leftmain = leftmain.strip()\n",
    "    lad = lad.strip()\n",
    "    circumflex = circumflex.strip()\n",
    "    rca = rca.strip()\n",
    "    \n",
    "    remove = (notestart == -1) | (leftmainstart == -1) | (ladstart == -1) | (circumflexstart == -1) | (rcastart == -1)\n",
    "    \n",
    "    return dominance, leftmain, lad, circumflex, rca, remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"dominance\", \"leftmain\", \"lad\", \"circumflex\", \"rca\", \"remove\"]] = df.apply(cathresults, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape                       #8724"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df[df['dominance']=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.shape                  #231 with mising dominance information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['remove'].value_counts()                          #5 additional patients with incomplete cath summary, all with RCA not injected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.remove.apply(lambda x: x)]   #remove rows with \"remove==True\"\n",
    "df = df.drop(\"remove\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape                        #8719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.leftmain.apply(lambda x: len(str(x)) > 5)] \n",
    "df = df[df.lad.apply(lambda x: len(str(x)) > 5)] \n",
    "df = df[df.circumflex.apply(lambda x: len(str(x)) > 5)] \n",
    "df = df[df.rca.apply(lambda x: len(str(x)) > 5)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape                       #8716"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Stenosis'].value_counts()        #7570 rows with stenosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftemp = df[df.dominance.apply(lambda x: len(str(x)) >15)]           #no vessel descriptions are excessively long\n",
    "dftemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftemp = df[df.leftmain.apply(lambda x: len(str(x)) >700)]\n",
    "dftemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftemp = df[df.lad.apply(lambda x: len(str(x)) >1000)]\n",
    "dftemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftemp = df[df.circumflex.apply(lambda x: len(str(x)) >1000)]\n",
    "dftemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftemp = df[df.rca.apply(lambda x: len(str(x)) >1000)]\n",
    "dftemp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.iloc[0].NoteTXT)                    #duplicates (i.e. index 0, 1, and 2) have same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset = 'NoteTXT', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape                                   #went from 8716 to 8629 after dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(df.iloc[0:1])                 #prints selected rows with full note text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('/mnt/obi0/phi/ehr/cath_reports/mgh_cathreports.parquet')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stenosis descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8629, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=('/mnt/obi0/phi/ehr/cath_reports/mgh_cathreports.parquet')  \n",
    "df = pd.read_parquet(file)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['NoteID', 'NoteCSNID', 'PatientID_x','dominance','leftmain', 'lad', 'circumflex', 'rca']]   #keeps only ids and vessel descriptions in df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(df.iloc[0:1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lad'] = df['lad'].str.replace(' {2,}', ' ')    #substitutes multiple spaces in LAD description paragraph with one space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lad'] = df['lad'].str.rstrip('.')              #removes periods at end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lad_sentence'] = df.lad.str.split(r'\\.(?=[^0-9])', expand=False)  #splits at periods except if the . is followed by a number (decimal); creates list of sentences in lad_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lad_sentence'] = df.lad_sentence.apply(lambda x: [y.strip() for y in x])  #removes space in front of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty(dframe):                     #removes empty sentences from lad_sentence\n",
    "    \n",
    "    lad_sents_all = dframe.lad_sentence\n",
    "    \n",
    "    for sent in lad_sents_all:\n",
    "        if sent == '':\n",
    "            lad_sents_all.remove(sent)\n",
    "    \n",
    "    return lad_sents_all\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lad_sentence']= df.apply(remove_empty, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['lad_sentence'][0:5])\n",
    "#or- df.iloc[0:5].lad_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []          #creates sentences, a list of lists used to create Dictionary later; each list is a patient's LAD description, with the sentences as separate strings\n",
    "\n",
    "for index, rows in df.iterrows():\n",
    "    sentences.append(rows.lad_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ladvessels = ['ramus','ostial','proximal','mid', 'distal','diag','d1','d2','d3','septal',' sp ','apical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separatevessels(dframe):       #separates each patient's LAD description sentences into separate lists depending on which vessel the group of sentences describes -> new column vessel_cat with list of lists\n",
    "    \n",
    "    lad_text = dframe.lad_sentence\n",
    "\n",
    "    vessel_cat = [['The entire LAD ']]  #first list element contains the string 'The entire LAD' (because first sentence sometimes starts with \"The vessel\" rather than \"The LAD\")                 \n",
    "\n",
    "    for sent in lad_text:\n",
    "        if any(x in sent[0:20].lower() for x in ladvessels):    #septal sometimes called \"sp\"\n",
    "            vessel_cat.append([])       #if sentence contains a word indicating a vessel, creates a new empty list element\n",
    "        vessel_cat[-1].append(sent)     #adds the sentence to the last list \n",
    "    \n",
    "    return vessel_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vessel_cat'] = df.apply(separatevessels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode('vessel_cat')      #separates into a separate row for each vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.vessel_cat.apply(lambda x: not(x[0]=='The entire LAD ' and len(x)==1))]     #removes rows that only have 'The entire LAD ' in vessel_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(df.iloc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = [chr(i) for i in range(ord('a'),ord('m')+1)]\n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ladprocess(dframe):               #extracts info from sentences describing each vessel\n",
    "    \n",
    "    lad_text = dframe.vessel_cat\n",
    "    \n",
    "    \n",
    "    matched = [None] * 13             #denotes entries that match one of the patterns below (for checking)\n",
    "    manual = [None] * 15              #denotes entries that need to be assessed manually\n",
    "    \n",
    "    remainder = []                    #list of sentences that do not fit one of the patterns below\n",
    "    \n",
    "    simplifiedsents = []              #contains sentences without the name of the vessel being described (to check if more than 1 vessel is being described)\n",
    "    \n",
    "    sent1start = lad_text[0][0:15]    #uses first 15 characters of first sentence to determine which vessel the sentences are about\n",
    "\n",
    "    arterydict = {'The entire LAD ' : 'LAD', 'The left anteri' : 'LAD', 'The Mid LAD has' : 'mid LAD', 'The Proximal LA' : 'prox LAD', 'The 1st Diagona' : 'D1', 'The Distal LAD ' : 'distal LAD', 'The 2nd Diagona' : 'D2', 'Left anterior d' : 'LAD', 'Mid LAD at the ' : 'mid LAD', 'Proximal LAD at' : 'prox LAD', 'The Mid LAD is ' : 'mid LAD', 'Distal LAD coro' : 'distal LAD', 'The ramus inter' : 'ramus', 'he 1st Diagonal' : 'D1', 'The artery cont' : 'LAD', 'he Mid LAD has ': 'mid LAD', 'The 3rd Diagona' : 'D3', 'The Ramus has a' : 'ramus', '1st Diagonal at' : 'D1', 'The distal LAD ' : 'distal LAD', 'Not imaged' : 'not imaged', 'The proximal LA' : 'prox LAD', 'he Proximal LAD': 'prox LAD', 'The first diago' : 'D1', 'The mid LAD has' : 'mid LAD', 'Distal LAD at t' : 'distal LAD', 'The second diag' : 'D2', 'he 2nd Diagonal' : 'D2', '1st Diagonal co' : 'D1', '2nd Diagonal co' : 'D2'}\n",
    "    try:\n",
    "        vessel = arterydict[sent1start]\n",
    "        vesselsentstart = sent1start\n",
    "    except KeyError:\n",
    "        vessel = 'manual'             #if the sentence does not have one of the standard sentence beginnings, labels the vessel as needing to be assessed manually\n",
    "        manual[0] = 1\n",
    "\n",
    "    \n",
    "    sten_type = ''\n",
    "    sten_percent = ''\n",
    "    sten_descriptor = ''\n",
    "    vessel_size = ''\n",
    "    lad_length = ''\n",
    "    lad_givesoff = ''\n",
    "    prior_type = ''\n",
    "    prior_status = ''\n",
    "    collat_from_extent = ''\n",
    "    collat_from = ''\n",
    "    collat_to_extent = ''\n",
    "    collat_to = ''\n",
    "    occlusion_point = ''\n",
    "    timi_flow = ''\n",
    "    lesion_continues = ''\n",
    "    \n",
    "    \n",
    "    for sent in lad_text:                     #assesses each sentence for the vessel\n",
    "        \n",
    "    \n",
    "        pattern_1 = re.search(r'has an? (?P<sten_type>[a-zA-Z \\,]*)? ?(?P<sten_percent>[0-9\\-]+) ?% stenosis? ?(?P<sten_descriptor>.*)?', sent)\n",
    "    \n",
    "        if pattern_1 and sten_percent=='':\n",
    "            sten_type = pattern_1.group(1)\n",
    "            sten_percent = pattern_1.group(2)\n",
    "            sten_descriptor = pattern_1.group(3)\n",
    "            matched[1] = 1\n",
    "        elif pattern_1:                               #if a value is already present in sten_percent (another sentence also gives a sten_percent value), then marks as having to be manual   \n",
    "            sten_type = 'manual'\n",
    "            sten_percent = 'manual'\n",
    "            sten_descriptor = 'manual'\n",
    "            manual[1] = 1\n",
    "            remainder.append(sent)\n",
    "\n",
    "\n",
    "        pattern_2 = re.search(r'descending artery is (.+) vessel(?:, which)?(.+ of the heart)?(?: and gives origin to )?(.+)?(\\.)?', sent)\n",
    "        \n",
    "        if pattern_2 and lad_length=='':\n",
    "            vessel_size = pattern_2.group(1)\n",
    "            lad_length = pattern_2.group(2)\n",
    "            lad_givesoff = pattern_2.group(3)\n",
    "            matched[2] = 1\n",
    "        elif pattern_2:\n",
    "            vessel_size = 'manual'\n",
    "            lad_length = 'manual'\n",
    "            lad_givesoff = 'manual'\n",
    "            manual[2] = 1\n",
    "            remainder.append(sent)\n",
    "        \n",
    "        \n",
    "        pattern_3 = re.search(r'at the site of previous intervention \\((.+)\\) (.+)', sent)\n",
    "        \n",
    "        if pattern_3 and prior_status=='':\n",
    "            prior_type = pattern_3.group(1)\n",
    "            prior_status = pattern_3.group(2)\n",
    "            matched[3] = 1\n",
    "        elif pattern_3:\n",
    "            prior_status = 'manual'\n",
    "            manual[3] = 1\n",
    "            remainder.append(sent)\n",
    "        \n",
    "        \n",
    "        pattern_4 = re.search(r'receives (.+) filling (?:through collaterals )?from (.+)', sent)\n",
    "        \n",
    "        if pattern_4 and collat_from=='':\n",
    "            collat_from_extent = pattern_4.group(1)\n",
    "            collat_from = pattern_4.group(2)\n",
    "            matched[4] = 1\n",
    "        elif pattern_4:\n",
    "            collat_from = 'manual'\n",
    "            manual[4] = 1\n",
    "            remainder.append(sent)\n",
    "            \n",
    "            \n",
    "        pattern_5 = re.search('(?:contains|has|are) (?:only )?(minimal|luminal|mild|mild luminal|minimal luminal|multiple luminal) irregulariti', sent)\n",
    "        \n",
    "        if pattern_5 and (sten_percent == '' or sten_percent == 'manual'):\n",
    "            sten_percent = 'minimal'\n",
    "            matched[5] = 1\n",
    "        elif pattern_5:\n",
    "            sten_percent = 'manual'\n",
    "            manual[5] = 1\n",
    "            remainder.append(sent)\n",
    "        \n",
    "        \n",
    "        pattern_6 = re.search('is norm', sent)\n",
    "        \n",
    "        if pattern_6 and (sten_percent == '' or sten_percent == 'manual'):\n",
    "            sten_percent = 'zero'\n",
    "            matched[6] = 1\n",
    "        elif pattern_6:\n",
    "            sten_percent = 'manual'\n",
    "            manual[6] = 1\n",
    "            remainder.append(sent)\n",
    "        \n",
    "        \n",
    "        pattern_7 = re.search('gives (.+) blood supply through collaterals to (.+)', sent)\n",
    "        \n",
    "        if pattern_7 and collat_to=='':\n",
    "            collat_to_extent = pattern_7.group(1)\n",
    "            collat_to = pattern_7.group(2)\n",
    "            matched[7] = 1\n",
    "        elif pattern_7:\n",
    "            collat_to = 'manual'\n",
    "            manual[7] = 1\n",
    "            remainder.append(sent)\n",
    "            \n",
    "            \n",
    "        pattern_8 = re.search(r'(?i)(not inj|not engag|not imag|not selec)', sent)\n",
    "        \n",
    "        if pattern_8 and sten_percent == '':\n",
    "            sten_percent = 'not injected'\n",
    "            matched[8] = 1\n",
    "        elif pattern_8:\n",
    "            sten_percent = 'manual'\n",
    "            manual[8] = 1\n",
    "            remainder.append(sent)\n",
    "        \n",
    "        \n",
    "        pattern_9 = re.search(r'is totally occluded ?(.*)?', sent)\n",
    "        \n",
    "        if pattern_9 and sten_percent == '':\n",
    "            sten_type = 'occluded'\n",
    "            if pattern_9.group(1) is not None:\n",
    "                occlusion_point = pattern_9.group(1)\n",
    "            matched[9] = 1\n",
    "        elif pattern_9:\n",
    "            sten_type = 'manual'\n",
    "            manual[9] = 1\n",
    "            remainder.append(sent)\n",
    "        \n",
    "        \n",
    "        pattern_10= re.search(r'TIMI flow through the lesion is (.+)', sent)\n",
    "        \n",
    "        if pattern_10:\n",
    "            timi_flow = pattern_10.group(1)\n",
    "            matched[10] = 1\n",
    "        \n",
    "        \n",
    "        pattern_11 = re.search('is (small|moderate sized|large)$', sent)\n",
    "        \n",
    "        if pattern_11 and vessel_size=='':\n",
    "            vessel_size = pattern_11.group(1)\n",
    "            matched[11] = 1\n",
    "        elif pattern_11:\n",
    "            vessel_size = 'manual'\n",
    "            manual[11] = 1\n",
    "            remainder.append(sent)\n",
    "        \n",
    "        \n",
    "        pattern_12 = re.search('This lesions? continues into (.+)', sent)\n",
    "        \n",
    "        if pattern_12 and lesion_continues == '':\n",
    "            lesion_continues = pattern_12.group(1)\n",
    "            matched[12] = 1\n",
    "        elif pattern_12:\n",
    "            lesion_continues = 'manual'\n",
    "            manual[12] = 1\n",
    "        \n",
    "        \n",
    "        #if not any(matched):\n",
    "        if not(pattern_1) and not(pattern_2) and not(pattern_3) and not(pattern_4) and not(pattern_5) and not(pattern_6) and not(pattern_7) and not(pattern_8) and not(pattern_9) and not(pattern_10) and not(pattern_11) and not(pattern_12) and sent!='The entire LAD ':       \n",
    "            remainder.append(sent)\n",
    "            manual[13] = 1\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            simplifiedsent = sent.replace(vesselsentstart, '').replace(sten_descriptor, '').replace(lad_givesoff, '').replace(collat_from, '').replace(collat_to, '').replace(occlusion_point, '').replace(lesion_continues, '') \n",
    "        except:\n",
    "            simplifiedsent = sent\n",
    "        \n",
    "        simplifiedsents.append(simplifiedsent)        \n",
    "        \n",
    "    \n",
    "    totalsents = ''.join(simplifiedsents)\n",
    "    if any(x in totalsents.lower() for x in ladvessels): \n",
    "        manual[14] = 1                        #manual[14] = 1 if more than 1 vessel is being described in the row\n",
    "        \n",
    "\n",
    "    return vessel, sten_type, sten_percent, sten_descriptor, vessel_size, lad_length, lad_givesoff, prior_type, prior_status, collat_from_extent, collat_from, collat_to_extent, collat_to, occlusion_point, timi_flow, lesion_continues, remainder, simplifiedsents, matched, manual\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['vessel', 'sten_type', 'sten_percent', 'sten_descriptor', 'vessel_size', 'lad_length', 'lad_givesoff', 'prior_type', 'prior_status', 'collat_from_extent', 'collat_from', 'collat_to_extent', 'collat_to', 'occlusion_point', 'timi_flow', 'lesion_continues', 'remainder', 'simplifiedsents', 'matched', 'manual']] = df.apply(ladprocess, axis=1, result_type = \"expand\")\n",
    "\n",
    "#df[['stent_type', 'sten_percent', 'sten_descriptor']] = df.apply(ladprocess, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16394, 31)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vesseldesc = df['sten_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['sten_type'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vesseldescs = []\n",
    "\n",
    "for i in range(len(vesseldesc)):\n",
    "    if (vesseldesc[i] > 1):\n",
    "        vesseldescs.append(vesseldesc.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'focal ', 'diffuse ', 'occluded', 'long ', 'tubular ', 'eccentric ', 'irregular ', 'hazy ', 'tandem ', 'calcified ', 'long and diffuse ', 'thrombotic ', 'eccentric and calcified ', 'mild ', 'manual', 'severely calcified ', 'focal and calcified ', 'diffuse and calcified ', 'long and tubular ', 'eccentric and focal ', 'focal and severely calcified ', 'long and eccentric ', 'focal and eccentric ', 'long and irregular ', 'tapering ', 'hazy and eccentric ', 'hazy and focal ', 'diffuse and long ', 'focal and hazy ', 'eccentric and diffuse ', 'irregular and long ', 'long irregular ', 'long and calcified ', 'tubular and long ', 'eccentric and tubular ', 'eccentric and irregular ', 'long up to ', 'irregular and diffuse ', 'diffuse and severely calcified ', 'eccentric and long ', 'focal, calcified ', 'long and tandem ', 'diffuse and irregular ', 'focal and thrombotic ', 'tubular and irregular ', 'irregularities ', 'diffuse up to ', 'focal, eccentric ', 'eccentric and hazy ', 'tubular and calcified ', 'tubular and diffuse ', 'hazy and thrombotic ', 'proximal ', 'hazy and irregular ', 'hazy and calcified ', 'mild and diffuse ', 'irregular and calcified ', 'eccentric, focal, and irregular ', 'tandem and focal ', 'long and hazy ', 'irregular and severely calcified ', 'long, calcified ', 'ulcerated ', 'eccentric, focal, and calcified ', 'concentric ', 'focal calcified ', 'diffuse and irregularities ', 'tubular and eccentric ', 'focal and tubular ', 'eccentric and severely calcified ', 'hazy, eccentric, and thrombotic ', 'irregular, hazy, and thrombotic ', 'severely calcified and diffuse ', 'hazey ', 'heavily thrombotic ', 'ostial ', 'long, irregular, and severely calcified ', 'focal, hazy ', 'calcified and tandem ', 'calcified and focal ', 'complex ', 'calcified and eccentric ', 'irregular and eccentric ', 'diffuse and tandem ', 'long, diffuse ', 'focal and tandem ', 'irregularities and diffuse ', 'tandem and diffuse ', 'tandem and calcified ', 'long tubular ', 'hazy and long ', 'long calcified ', 'calcified eccentric ', 'tubular and moderately calcified ', 'diffuse and mild ', 'approximately ', 'hazy, eccentric, and tubular ', 'focal complex ', 'long, subtotal ', 'eccentric, hazy, and focal ', 'eccentric, diffuse, and severely calcified ', 'tandem, calcified ', 'indeterminate ', 'focal eccentric ', 'irregular, diffuse, and calcified ', 'severe tandem ', 'long irrgular ', 'focal, long ', 'eccentric, irregular, and tandem ', 'severe, long, calcific, tapering ', 'eccentric and thrombotic ', 'tubular, eccentric ', 'eccentric and tapering ', 'tubular and severely calcified ', 'long, tubular ', 'diffuse and eccentric ', 'eccentric, tubular, and calcified ', 'eccentric, complex ', 'hazy and tubular ', 'hazy and diffuse ', 'eccentric ulcerated ', 'plaque associated with a ', 'focal and long ', 'tandem, long ']\n"
     ]
    }
   ],
   "source": [
    "print(vesseldescs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = [\"h i\", \"hel lo\", \"ho la\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'i']\n",
      "['hel', 'lo']\n",
      "['ho', 'la']\n"
     ]
    }
   ],
   "source": [
    "for i in hello:\n",
    "    words = i.split(' ')\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words = [i.split(' ') for i in hello]\n",
    "#words = [i.split(', ') for i in vesseldescs]\n",
    "vesselde = []\n",
    "\n",
    "for i in vesseldescs:\n",
    "    i = i.strip()\n",
    "    vesselde.extend(re.split(' ',i))     #(', | and ',i))\n",
    "#for vesseld in vesseldescs:\n",
    "    #vesseld.split(',')\n",
    "    #vesseld.strip(',')\n",
    "    #vesseld.strip(' ')\n",
    "    #for vesselds in vesseld:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "vesselde = [i.strip(',') for i in vesselde]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "vesscounts = dict()\n",
    "for i in vesselde:\n",
    "    vesscounts[i] = vesscounts.get(i, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 1, 'focal': 23, 'diffuse': 22, 'occluded': 1, 'long': 27, 'tubular': 17, 'eccentric': 32, 'irregular': 17, 'hazy': 17, 'tandem': 12, 'calcified': 31, 'and': 73, 'thrombotic': 7, 'mild': 3, 'manual': 1, 'severely': 9, 'tapering': 3, 'up': 2, 'to': 2, 'irregularities': 3, 'proximal': 1, 'ulcerated': 2, 'concentric': 1, 'hazey': 1, 'heavily': 1, 'ostial': 1, 'complex': 3, 'moderately': 1, 'approximately': 1, 'subtotal': 1, 'indeterminate': 1, 'severe': 2, 'irrgular': 1, 'calcific': 1, 'plaque': 1, 'associated': 1, 'with': 1, 'a': 1}\n"
     ]
    }
   ],
   "source": [
    "print(vesscounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: \n",
      "1: a\n",
      "73: and\n",
      "1: approximately\n",
      "1: associated\n",
      "1: calcific\n",
      "31: calcified\n",
      "3: complex\n",
      "1: concentric\n",
      "22: diffuse\n",
      "32: eccentric\n",
      "23: focal\n",
      "1: hazey\n",
      "17: hazy\n",
      "1: heavily\n",
      "1: indeterminate\n",
      "17: irregular\n",
      "3: irregularities\n",
      "1: irrgular\n",
      "27: long\n",
      "1: manual\n",
      "3: mild\n",
      "1: moderately\n",
      "1: occluded\n",
      "1: ostial\n",
      "1: plaque\n",
      "1: proximal\n",
      "2: severe\n",
      "9: severely\n",
      "1: subtotal\n",
      "12: tandem\n",
      "3: tapering\n",
      "7: thrombotic\n",
      "2: to\n",
      "17: tubular\n",
      "2: ulcerated\n",
      "2: up\n",
      "1: with\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(vesscounts):          #prints out dictionary\n",
    "    print(\"%s: %s\" % (vesscounts[key], key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vesselde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vesseldescs.split(',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vesseldescs.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vesseldescs.strip(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'focal ', 'diffuse ', 'occluded', 'long ', 'tubular ', 'eccentric ', 'irregular ', 'hazy ', 'tandem ', 'calcified ', 'long and diffuse ', 'thrombotic ', 'eccentric and calcified ', 'mild ', 'manual', 'severely calcified ', 'focal and calcified ', 'diffuse and calcified ', 'long and tubular ', 'eccentric and focal ', 'focal and severely calcified ', 'long and eccentric ', 'focal and eccentric ', 'long and irregular ', 'tapering ', 'hazy and eccentric ', 'hazy and focal ', 'diffuse and long ', 'focal and hazy ', 'eccentric and diffuse ', 'irregular and long ', 'long irregular ', 'long and calcified ', 'tubular and long ', 'eccentric and tubular ', 'eccentric and irregular ', 'long up to ', 'irregular and diffuse ', 'diffuse and severely calcified ', 'eccentric and long ', 'focal, calcified ', 'long and tandem ', 'diffuse and irregular ', 'focal and thrombotic ', 'tubular and irregular ', 'irregularities ', 'diffuse up to ', 'focal, eccentric ', 'eccentric and hazy ', 'tubular and calcified ', 'tubular and diffuse ', 'hazy and thrombotic ', 'proximal ', 'hazy and irregular ', 'hazy and calcified ', 'mild and diffuse ', 'irregular and calcified ', 'eccentric, focal, and irregular ', 'tandem and focal ', 'long and hazy ', 'irregular and severely calcified ', 'long, calcified ', 'ulcerated ', 'eccentric, focal, and calcified ', 'concentric ', 'focal calcified ', 'diffuse and irregularities ', 'tubular and eccentric ', 'focal and tubular ', 'eccentric and severely calcified ', 'hazy, eccentric, and thrombotic ', 'irregular, hazy, and thrombotic ', 'severely calcified and diffuse ', 'hazey ', 'heavily thrombotic ', 'ostial ', 'long, irregular, and severely calcified ', 'focal, hazy ', 'calcified and tandem ', 'calcified and focal ', 'complex ', 'calcified and eccentric ', 'irregular and eccentric ', 'diffuse and tandem ', 'long, diffuse ', 'focal and tandem ', 'irregularities and diffuse ', 'tandem and diffuse ', 'tandem and calcified ', 'long tubular ', 'hazy and long ', 'long calcified ', 'calcified eccentric ', 'tubular and moderately calcified ', 'diffuse and mild ', 'approximately ', 'hazy, eccentric, and tubular ', 'focal complex ', 'long, subtotal ', 'eccentric, hazy, and focal ', 'eccentric, diffuse, and severely calcified ', 'tandem, calcified ', 'indeterminate ', 'focal eccentric ', 'irregular, diffuse, and calcified ', 'severe tandem ', 'long irrgular ', 'focal, long ', 'eccentric, irregular, and tandem ', 'severe, long, calcific, tapering ', 'eccentric and thrombotic ', 'tubular, eccentric ', 'eccentric and tapering ', 'tubular and severely calcified ', 'long, tubular ', 'diffuse and eccentric ', 'eccentric, tubular, and calcified ', 'eccentric, complex ', 'hazy and tubular ', 'hazy and diffuse ', 'eccentric ulcerated ', 'plaque associated with a ', 'focal and long ', 'tandem, long ']\n"
     ]
    }
   ],
   "source": [
    "print(vesseldescs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['sten_type'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1833, 31)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftemp = df[df.manual.apply(lambda x: 1 in x)]          #shows rows where manual contains 1 in any position\n",
    "dftemp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(dftemp.iloc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1099, 31)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftemp = df[df.manual.apply(lambda x: x[14]==1)]        #shows rows where manual contains 1 in a certain position\n",
    "dftemp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(dftemp.iloc[20:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 31)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftemp = df[df.matched.apply(lambda x: x[12]==1)]        #shows rows where matched contains 1 in a certain position\n",
    "dftemp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(dftemp.iloc[0:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remainder_sentences = []                            #creates a list with a list for each cath description, which contains sentences as separate strings\n",
    "\n",
    "for index, rows in df.iterrows():\n",
    "    remainder_sentences.extend(rows.remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['manual_review'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(remainder_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remainder_sentences[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remainder_sentcounts = dict()\n",
    "for i in remainder_sentences:\n",
    "    remainder_sentcounts[i] = remainder_sentcounts.get(i, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(remainder_sentcounts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sorted(remainder_sentcounts):          #prints out dictionary\n",
    "    if remainder_sentcounts[key] >5:\n",
    "        print(\"%s: %s\" % (remainder_sentcounts[key], key)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []                            #creates a list with a list for each cath description, which contains sentences as separate strings\n",
    "\n",
    "for index, rows in df.iterrows():\n",
    "    sentences.append(rows.lad_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_cat = [[]]                        #separates each list into separate lists depending on which vessel the group of sentences describes\n",
    "\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        #if re.search('mid', 'distal', re.IGNORECASE):\n",
    "        if any(x in i[0:20].lower() for x in ('ramus','ostial','proximal','mid', 'distal','diag','d1','d2','d3','septal')):\n",
    "            vessel_cat.append([])\n",
    "        vessel_cat[-1].append(i)\n",
    "    vessel_cat.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_cat = [x for x in vessel_cat if x]         #removes empty lists within vessel_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ves_sents in vessel_cat:                  #check\n",
    "    if (any(x in ves_sents[0][0:20].lower() for x in ('the artery', 'imaged', 'injected', 'anterior', 'lad','ramus','ostial','proximal','mid', 'distal','diag','d1','d2','d3','septal')))==False:\n",
    "        print(ves_sents[0])\n",
    "#no unusual beginnings to territory sentences    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_cat[0:5]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ves_sents in vessel_cat:                    #check  \n",
    "    for ves_sent in ves_sents:\n",
    "        if any(x in ves_sent[0:20].lower() for x in ('anterior', 'lad', 'ramus','ostial','proximal','mid', 'distal','diag','d1','d2','d3','septal')):\n",
    "            print(ves_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ves_sents in vessel_cat:                    #check\n",
    "    for ves_sent in ves_sents:\n",
    "        if ves_sent.startswith('The artery'):         \n",
    "            if len(ves_sents)>2:\n",
    "                print(ves_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vessel_cat = ['. '.join(map(str,x)) for x in vessel_cat]                    #joins sentences for each vessel together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_cat[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.DataFrame(vessel_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.columns = ['sent1', 'sent2', 'sent3', 'sent4', 'sent5'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(df3.iloc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['sent1start'] = df3['sent1'].str[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentstarts = df3['sent1start'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentstarts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentstarts.to_string())            #prints full series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standsentstarts = []\n",
    "\n",
    "for i in range(len(sentstarts)):\n",
    "    if (sentstarts[i] > 10):\n",
    "        standsentstarts.append(sentstarts.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(standsentstarts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df.sent1start.apply(lambda x: any(standstart in x for standstart in standsentstarts))]       #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df.sent1start.apply(lambda x: 'Moderate calibe' in x)]             #check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arterydict = {'The left anteri' : 'LAD', 'The Mid LAD has' : 'mid LAD', 'The Proximal LA' : 'prox LAD', 'The 1st Diagona' : 'D1', 'The Distal LAD ' : 'distal LAD', 'The 2nd Diagona' : 'D2', 'Left anterior d' : 'LAD', 'Mid LAD at the ' : 'mid LAD', 'Proximal LAD at' : 'prox LAD', 'The Mid LAD is ' : 'mid LAD', 'Distal LAD coro' : 'distal LAD', 'The ramus inter' : 'ramus', 'he 1st Diagonal' : 'D1', 'The artery cont' : 'LAD', 'he Mid LAD has ': 'mid LAD', 'The 3rd Diagona' : 'D3', 'The Ramus has a' : 'ramus', '1st Diagonal at' : 'D1', 'The distal LAD ' : 'distal LAD', 'Not imaged' : 'not imaged', 'The proximal LA' : 'prox LAD', 'he Proximal LAD': 'prox LAD', 'The first diago' : 'D1', 'The mid LAD has' : 'mid LAD', 'Distal LAD at t' : 'distal LAD', 'The second diag' : 'D2', 'he 2nd Diagonal' : 'D2'}\n",
    "\n",
    "df3['vessel'] = df3['sent1start'].map(arterydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[['stent_type','sten_percent','sten_descriptor']] = df3['sent1'].str.extract(r'has a (?P<sten_type>[a-zA-Z]*) (?P<sten_percent>[0-9]+) % stenosis (?P<sten_descriptor>.*)', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(df3.iloc[5:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stendescriptors = df3['sten_descriptor'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stendescriptors.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['lad_size','lad_length','lad_givesoff']] = df['sent1'].str.extract(r'descending artery is (.+) vessel(?:, which)?(.+ of the heart)?(?: and gives origin to )?(.+)?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(df.iloc[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ladsize = df['lad_length'].value_counts()\n",
    "print(ladsize.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at the site of previous intervention (Balloon Only) is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['stenosis'] = df['sentence'].str.contains(r'(.+has a .+stenosis)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_all = [item for sublist in sentences for item in sublist]               #flattens list of lists into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences_all[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sentences_all:\n",
    "    i.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sentences_all))               #total 23,612 left main sentences, 20,020 LAD sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentcounts = dict()\n",
    "for i in sentences_all:\n",
    "    sentcounts[i] = sentcounts.get(i, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentcounts)                         #1,368 unique sentences describing left main; 5,247 unique sentences describing LAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sorted(sentcounts):          #prints out dictionary\n",
    "    print(\"%s: %s\" % (sentcounts[key], key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.DataFrame.from_dict(sentcounts, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['sentence'] = dfs.index\n",
    "dfs.reset_index(drop=True, inplace=True)\n",
    "dfs.columns = ['count', 'sentence']\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['sentence'] = dfs['sentence'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentparse(dfs, terr):                              #incomplete\n",
    "    \n",
    "    sent = dfs.sentence\n",
    "    \n",
    "    vessel = 0\n",
    "    ost = 0\n",
    "    proximal = 0\n",
    "    mid = 0\n",
    "    not_inj = 0\n",
    "    focal = 0\n",
    "    diffuse = 0\n",
    "    percent = 0\n",
    "    \n",
    "    if 'selectively' in sent:\n",
    "        not_inj = 1\n",
    "        vessel = 'all'\n",
    "        ost = terr\n",
    "\n",
    "    \n",
    "    return vessel, ost, proximal, mid, not_inj, focal, diffuse, percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#goes with above cell\n",
    "dfs[[\"vessel\", \"ost\", \"proximal\", \"mid\", \"not_inj\", \"focal\", \"diffuse\", \"percent\"]] = dfs.apply(sentparse, terr = 'lad', axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration (Preliminary steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"/mnt/obi0/phi/ehr/note_pull/parquet/MGH_cath_2018-09%_notes_pulled_10-12-2019.parquet\"\n",
    "df_orig= pd.read_parquet(file)\n",
    "df = df_orig.copy()     #necessary?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(by=['PatientID'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_patients = df['PatientID'].nunique()\n",
    "print(unique_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['NoteTXT'].str.contains('CARDIAC CATHETERIZATION LABORATORY FINAL REPORT', case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(df2.iloc[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_patients = df2['PatientID'].nunique()\n",
    "print(unique_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = df['PatientID'].unique()\n",
    "array2 = df2['PatientID'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(array2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.in1d(array1,array2, invert=True)\n",
    "mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array3 = array1[mask]             #patients in df1 but not in df2 (patients who don't have any cath reports)\n",
    "array3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df[df['PatientID'].isin(array3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(df3.iloc[0:2])      #appears to mostly have EP procedure notes, and some with prelim cath reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df2[df2['NoteTXT'].str.contains('discharge summary', case=False)]\n",
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df2[df2['NoteTXT'].str.contains('transplant|SVG|LIMA', case=False)]\n",
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(df5.iloc[0:2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df2[~df2['NoteTXT'].str.contains('transplant|SVG|LIMA', case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(df6.iloc[0:2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df6[~df6['NoteTXT'].str.contains('LAD|\"left anterior descending\"', case=False)]\n",
    "df7.shape                   #RHC and pericardiocenteses contain \"Diagnostic Attending\" so \"diagnostic\" not used as a criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(df7.iloc[0:2])                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = df6[df6['NoteTXT'].str.contains('LAD|\"left anterior descending\"', case=False)]\n",
    "df9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print(df9.iloc[0:2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = df9[df9['NoteTXT'].str.contains('stenosis|stenoses', case=False)]\n",
    "df10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df10[df10['NoteTXT'].str.contains('\"no stenosis\"|\"no stenoses\"', case=False)]\n",
    "df11.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discarded cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not necessary\n",
    "dftemp = df.NoteTXT.str.extract(r'(RCA:)')\n",
    "dftemp.head()\n",
    "dftemp.isnull().values.any()\n",
    "#df[\"Dominance\"] = df[\"NoteTXT\"].str.extract(r'(Dominance:.+Left Main:)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2]['lad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1188:1189]\n",
    "#len(str(dftemp.iloc[0]['circumflex']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"index2\"] = df[\"NoteTXT\"].str.find('LAD', start = df[\"NoteTXT\"]str.find('CORONARY ANATOMY FINDINGS'))\n",
    "df[\"Dominance\"] = df[\"NoteTXT\"].str.extract(r'(Dominance:.+Left Main:)')\n",
    "#df[\"Dominance\"] = df[\"Dominance\"].str.replace('Dominance: ', '')\n",
    "#df[\"Dominance\"] = df[\"Dominance\"].str.replace(' Left Main:', '')\n",
    "#df[\"Dominance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Left Main\"] = df[\"NoteTXT\"].str.extract(r'(Left Main:.+LAD:)')\n",
    "df[\"Left Main\"] = df[\"Left Main\"].str.replace('Left Main: ', '')\n",
    "df[\"Left Main\"] = df[\"Left Main\"].str.replace(' LAD:', '')\n",
    "df[\"Left Main\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"LAD\"] = df[\"NoteTXT\"].str.extract(r'(LAD:.+Circumflex:|LCx)')\n",
    "df[\"LAD\"] = df[\"LAD\"].str.replace('LAD: ', '')\n",
    "df[\"LAD\"] = df[\"LAD\"].str.replace('Left Circumflex: ', '')\n",
    "df[\"LAD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Circumflex\"] = df[\"NoteTXT\"].str.extract(r'(Circumflex:.+RCA:)')\n",
    "df[\"Circumflex\"] = df[\"Circumflex\"].str.replace('Circumflex: ', '')\n",
    "df[\"Circumflex\"] = df[\"Circumflex\"].str.replace('RCA: ', '')\n",
    "df[\"Circumflex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"RCA\"] = df[\"NoteTXT\"].str.extract(r'(RCA:.+(DECISION|EQUIPMENT))')\n",
    "df[\"RCA\"] = df[\"RCA\"].str.replace('RCA: ', '')\n",
    "df[\"RCA\"] = df[\"RCA\"].str.replace('DECISION ', '')\n",
    "df[\"RCA\"] = df[\"RCA\"].str.replace('EQUIPMENT ', '')\n",
    "df[\"RCA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.groupby(\"NoteID\").apply(lambda x: x.NoteTXT.str.find(\"LAD\", start = x.NoteTXT.str.find('CORONARY ANATOMY FINDINGS')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('/mnt/obi0/phi/ehr/cath_reports/MGH_cath_stenoses.txt').touch() \n",
    "\n",
    "with open('/mnt/obi0/phi/ehr/cath_reports/MGH_cath_stenoses.txt', 'w') as outfile:\n",
    "    for datefile in Path('/mnt/obi0/phi/ehr/cath_reports/').glob('MGH_cath_stenosis_*'):\n",
    "        with open(datefile) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdates = pd.read_csv('/mnt/obi0/phi/ehr/cath_reports/MGH_cath_stenoses.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterables = [['ostial', 'proximal', 'mid', 'distal', 'd1', 'd2', 'd3'], ['not_inj', 'normal', 'focal', 'diffuse', 'calcified', 'eccentric', 'irregular', 'percent', 'prior_pci']]\n",
    "             \n",
    "cols = pd.MultiIndex.from_product(iterables, names=['vessel', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsdf = pd.DataFrame(np.zeros(shape=(8629, 63)), columns=cols)    #random.randn(8629, 30), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsdf = colsdf.astype(int)\n",
    "colsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.concat([dfs, colsdf], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(sentences)):\n",
    "    print(sentences[x], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in dfs['sentence']:\n",
    "    d[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sentdf.xs('not_inj', level = 'description', axis=1) = sentdf['sentence'].str.contains('Not selectively imaged')\n",
    "\n",
    "dfs.loc[:, ('ostial', 'not_inj')] = dfs['sentence'].str.contains('Not selectively imaged')\n",
    "dfs.loc[:, ('proximal', 'not_inj')] = dfs['sentence'].str.contains('Not selectively imaged')\n",
    "dfs.loc[:, ('mid', 'not_inj')] = dfs['sentence'].str.contains('Not selectively imaged')\n",
    "dfs.loc[:, ('distal', 'not_inj')] = dfs['sentence'].str.contains('Not selectively imaged')\n",
    "dfs.loc[:, ('d1', 'not_inj')] = dfs['sentence'].str.contains('Not selectively imaged')\n",
    "dfs.loc[:, ('d2', 'not_inj')] = dfs['sentence'].str.contains('Not selectively imaged')\n",
    "dfs.loc[:, ('d3', 'not_inj')] = dfs['sentence'].str.contains('Not selectively imaged')\n",
    "\n",
    "if dfs['sentence'].str.contains('.+has a.+stenosis'):\n",
    "    dfs.loc[:, ('ostial', 'not_inj')] = 1\n",
    "\n",
    "#sentdf.loc[:, 'not_inj'] =1\n",
    "\n",
    "#sentdf.loc(axis=1)[:, ['not_inj','focal']] = 1 #sentdf['sentence'].str.contains('Not selectively imaged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstyler = sentdf.style.set_properties(**{'text-align': 'left'})\n",
    "dfstyler.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vessel'] = df['sentence'].apply(lambda x: 'lad' if 'LAD' in x else 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
